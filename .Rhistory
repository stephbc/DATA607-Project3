geom_bar(stat='identity')
ggplot(Top_ten_skills, aes(x=reorder(Skills, n), y = n), fill=n)+
geom_bar(stat='identity')
ggplot(Top_ten_skills, aes(x=reorder(Skills, n), y = n, fill=n))+
geom_bar(stat='identity')
ggplot(Top_ten_skills, aes(x=reorder(Skills, n), y = n, fill=n))+
geom_bar(stat='identity') +
labs(title='Top 10 data science skills from LinkedIn job posting 2024',
x="", y='Number of postings')
ggplot(Top_ten_skills, aes(x=reorder(Skills, n), y = n, fill=n))+
geom_bar(stat='identity') +
labs(title='Top 10 data science skills from LinkedIn job posting 2024',
x="", y='Number of postings')+
theme(axis.text.x = element_text(angle=45, hjust = 1))
ggplot(Top_ten_skills, aes(x=reorder(Skills, n), y = n, fill=n))+
geom_bar(stat='identity') +
labs(title='Top 10 data science skills from LinkedIn job posting 2024',
x="", y='Number of postings')+
theme(axis.text.x = element_text(angle=45, hjust = 1),
legend.box = 'none')
ggplot(Top_ten_skills, aes(x=reorder(Skills, n), y = n, fill=n))+
geom_bar(stat='identity') +
labs(title='Top 10 data science skills from LinkedIn job posting 2024',
x="", y='Number of postings')+
theme(axis.text.x = element_text(angle=45, hjust = 1),
legend.box = none)
ggplot(Top_ten_skills, aes(x=reorder(Skills, n), y = n, fill=n))+
geom_bar(stat='identity') +
labs(title='Top 10 data science skills from LinkedIn job posting 2024',
x="", y='Number of postings')+
theme(axis.text.x = element_text(angle=45, hjust = 1),
legend.position='')
ggplot(Top_ten_skills, aes(x=reorder(Skills, n), y = n, fill=n))+
geom_bar(stat='identity') +
labs(title='Top 10 data science skills from LinkedIn job posting 2024',
x="", y='Number of postings')+
theme(axis.text.x = element_text(angle=47, hjust = 1),
legend.position='')
ggplot(Top_ten_skills, aes(x=reorder(Skills, n), y = n, fill=n))+
geom_bar(stat='identity') +
labs(title='Top 10 data science skills from LinkedIn job posting 2024',
x="", y='Number of postings')+
theme(axis.text.x = element_text(angle=47, hjust = 1),
legend.position='') +
coord_flip()
view(Skills_Normalized)
Skills_Normalized%>%
count(Skills)
Skills_Normalized%>%
count(Skills)
ggplot(Top_ten_skills, aes(x=reorder(Skills, n), y = n, fill=n))+
geom_bar(stat='identity') +
labs(title='Top 5 data science skills from LinkedIn job posting 2024',
x="", y='Number of postings')+
theme(axis.text.x = element_text(angle=47, hjust = 1),
legend.position='') +
coord_flip()
Top_ten_skills<- job_skills_clean %>%
count(Skills) %>%
slice_max(n, n=5)
ggplot(Top_ten_skills, aes(x=reorder(Skills, n), y = n, fill=n))+
geom_bar(stat='identity') +
labs(title='Top 5 data science skills from LinkedIn job posting 2024',
x="", y='Number of postings')+
theme(axis.text.x = element_text(angle=47, hjust = 1),
legend.position='') +
coord_flip()
View(job_skills_clean)
Top_ten_skills<- job_skills_clean %>%
count(Skills) %>%
slice_max(n, n=10)
ggplot(Top_ten_skills, aes(x=reorder(Skills, n), y = n, fill=n))+
geom_bar(stat='identity') +
labs(title='Top 5 data science skills from LinkedIn job posting 2024',
x="", y='Number of postings')+
theme(axis.text.x = element_text(angle=47, hjust = 1),
legend.position='') +
coord_flip()
job_skills_clean %>%
filter(grepl("SKILLS", Skills, ignore.case=TRUE))
job_skills_clean %>%
gsub("SKILS", "", Skills)
test<- gsub("SKILS", "", job_skills_clean$Skills)
test
test %>%
filter(grepl("SKILL", Skills))
test %>%
filter(grepl("SKILL", Skills, ignore.case=TRUE))
job_skills_clean$Skills<- gsub("SKILS", "", job_skills_clean$Skills)
job_skills_clean$Skills %>%
filter(grepl("SKILL", Skills, ignore.case=TRUE))
job_skills_clean
view(job_skills_clean)
Top_ten_skills<- job_skills_clean %>%
count(Skills) %>%
slice_max(n, n=10)
ggplot(Top_ten_skills, aes(x=reorder(Skills, n), y = n, fill=n))+
geom_bar(stat='identity') +
labs(title='Top 5 data science skills from LinkedIn job posting 2024',
x="", y='Number of postings')+
theme(axis.text.x = element_text(angle=47, hjust = 1),
legend.position='') +
coord_flip()
c
Top_ten_skills<- job_skills_clean %>%
count(Skills) %>%
slice_max(n, n=10)
ggplot(Top_ten_skills, aes(x=reorder(Skills, n), y = n, fill=n))+
geom_bar(stat='identity') +
labs(title='Top 5 data science skills from LinkedIn job posting 2024',
x="", y='Number of postings')+
theme(axis.text.x = element_text(angle=47, hjust = 1),
legend.position='') +
coord_flip()
head(job_postings)
?merge
view(job_postings)
job_postings %>%
filter(job_level=='Mid senior')
senior_lv<- job_postings %>%
filter(job_level=='Mid senior')
senior_lv<- job_postings_clean %>%
filter(job_level=='Mid senior')
senior_skills<- job_skills_clean %>%
merge(senior_lv, byintersect(names(job_ID)))
senior_skills<- job_skills_clean %>%
merge(senior_lv, by= intersect(names(job_ID)))
senior_lv$job_ID
senior_skills<- job_skills_clean %>%
filter(job_ID=='2690930489') %>%
left_join(senior_lv)
senior_skills
hist(senior_skills)
barplot(senior_skills)
ggplot(senior_skills, aes(x=Skills))+
geom_histogram()
senior_skills
senior_skills<- job_skills_clean %>%
filter(job_ID=='2690930489') %>%
left_join(senior_lv) %>%
count(Skills)
senior_skills<- job_skills_clean %>%
filter(job_ID=='2690930489') %>%
left_join(senior_lv) %>%
mutate(total=count(Skills))
senior_skills<- job_skills_clean %>%
filter(job_ID=='2690930489') %>%
left_join(senior_lv) %>%
mutate(total=sum(Skills))
senior_skills<- job_skills_clean %>%
filter(job_ID=='2690930489') %>%
left_join(senior_lv) %>%
count(Skills))
senior_skills<- job_skills_clean %>%
filter(job_ID=='2690930489') %>%
left_join(senior_lv) %>%
count(Skills)
senior_skills
senior_skills<- job_skills_clean %>%
left_join(senior_lv) %>%
group_by(Skills) %>%
count(Skills)
senior_skills
senior_skills<- job_skills_clean %>%
left_join(senior_lv) %>%
group_by(Skills) %>%
slice_max(n, n=5)
senior_skills<- job_skills_clean %>%
left_join(senior_lv) %>%
group_by(Skills) %>%
count(Skills) %>%
slice_max(n, n=5)
senior_skills
senior_skills<- job_skills_clean %>%
left_join(senior_lv) %>%
count(Skills) %>%
slice_max(n, n=5)
senior_skills
ggplot(senior_skills, aes(x=Skills, y=n))+
geom_bar()
ggplot(senior_skills, aes(x=Skills, y=n))+
geom_bar()
ggplot(senior_skills, aes(x=Skills, y=n))+
geom_bar(stat='identity')
ggplot(senior_skills, aes(x=reorder(Skills, n), y=n))+
geom_bar(stat='identity')
asso_lv<- job_postings_clean %>%
filter(job_level=='Associate')
assoc_skills<- job_skills_clean %>%
left_join(asso_lv) %>%
count(Skills) %>%
slice_max(n, n=5)
ggplot(assoc_skills, aes(x=reorder(Skills, n), y=n))+
geom_bar(stat='identity')
senior_skills<- job_skills_clean %>%
left_join(senior_lv) %>%
count(Skills) %>%
slice_max(n, n=10)
ggplot(senior_skills, aes(x=reorder(Skills, n), y=n))+
geom_bar(stat='identity')
View(job_postings_clean)
job_postings_clean %>%
group_by(State_or_Province) %>%
summarise(num=sum(n(State_or_Province)))
job_postings_clean %>%
group_by(State_or_Province) %>%
summarise(num=n(State_or_Province))
job_postings_clean %>%
group_by(State_or_Province) %>%
count(State_or_Province)
job_postings_clean %>%
drop_na(State_or_Province) %>%
group_by(State_or_Province) %>%
count(State_or_Province)
job_postings_clean %>%
drop_na(State_or_Province) %>%
group_by(State_or_Province) %>%
count(State_or_Province) %>%
slice_max(n, n=5)
job_postings_clean %>%
drop_na(State_or_Province) %>%
count(State_or_Province) %>%
slice_max(n, n=5)
job_num<- job_postings_clean %>%
drop_na(State_or_Province) %>%
count(State_or_Province) %>%
slice_max(n, n=5)
job_num
ggplot(job_num, aes(x=reorder(State_or_Province, n), y=n))+
geom_bar(stat='identity')
job_num<- job_postings_clean %>%
drop_na(State_or_Province) %>%
filter(Country=='United States') %>%
count(State_or_Province) %>%
slice_max(n, n=5)
ggplot(job_num, aes(x=reorder(State_or_Province, n), y=n))+
geom_bar(stat='identity')
ggplot(job_num, aes(x=reorder(State_or_Province, n), y=n, fill=n))+
geom_bar(stat='identity')
head(Skills_Normalized)
head(Company_Normalized)
library(tidyverse)
# Loading job_skills.csv and load into dataframe job_skills
file<-"https://raw.githubusercontent.com/stephbc/DATA607-Project3/refs/heads/main/job_skills.csv"
job_skills<-read.csv(file, sep=',')
# Loading job_poastings.csv and load into dataframe job_postings
file <- "https://raw.githubusercontent.com/stephbc/DATA607-Project3/refs/heads/main/job_postings.csv"
job_postings <- read.csv(file, sep=',')
#create a function to extract the ID numbers from the job_link:
id<- function(df) {
stringr::str_extract(df, "(\\d)+$")
}
#transform and rename job_link to job_ID:
job_skills$job_link<-id(job_skills$job_link)
names(job_skills)[names(job_skills)=='job_link'] <-"job_ID"
# Remove duplicate job_ID
job_skills <- job_skills %>%
group_by(job_ID) %>%
slice(1) %>%
ungroup()
#separate the skills:
job_skills_clean<- job_skills %>%
separate_wider_delim(job_skills, delim=',',
names_sep = '_',
too_few = 'align_start')
#pivot_longer to put all skills into one column:
job_skills_clean<- job_skills_clean %>%
pivot_longer(cols = starts_with("job_skills"),
names_to = 'Sets',
values_to = 'Skills',
values_drop_na = TRUE)
# Cleaning up the data in skills
# trim white space
job_skills_clean$Skills <- trimws(job_skills_clean$Skills)
# set empty spaces to null
job_skills_clean$Skills <- na_if(job_skills_clean$Skills, "")
# change all cases to upper case so when we group by case is not a factor
job_skills_clean$Skills <- toupper(job_skills_clean$Skills)
# Drop the sets column
job_skills_clean <- job_skills_clean %>% select(-c(Sets))
head(job_skills_clean)
# Using the function created before to change job_link to job_id
job_postings$job_link <- id(job_postings$job_link)
names(job_postings)[names(job_postings)=='job_link'] <-"job_ID"
# Extract the columns we need
job_postings<-job_postings[-c(3:6, 10:11)]
# Remove duplicate job_ID
job_postings <- job_postings %>%
group_by(job_ID) %>%
slice(1) %>%
ungroup()
#  Set of pattern for Countries and States
Countries <- c("Australia", "Canada", "Italy", "Mexico", "United Kingdom", "United States")
Countries <- paste(Countries, collapse = "|")
States <- c("DC" , "AL" , "AK" , "AS" , "AZ" , "AR" , "CA" , "CO" , "CT" , "DE" , "FL" , "GA" , "GU" ,
"HI" , "ID" , "IL" , "IN" , "IA" , "KS" , "KY" , "LA" , "ME" , "MD" , "MA" , "MI" , "MN" ,
"MS" , "MO" , "MT" , "NE" , "NV" , "NH" , "NJ" , "NM" , "NY" , "NC" , "ND" , "OH" , "OK" ,
"OR" , "PA" , "PR" , "RI" , "SC" , "SD" , "TN" , "TX" , "UT" , "VT" , "VA" , "WA" , "WV" ,
"WI" , "WY")
States <- paste(States, collapse = "|")
#-------------------------------------------------------------------
# job_location can be read as City, State/Province, and Country separated by ","
# but this column has entries where it's missing either entry so we first have
# to split the job_location by deliminator then check:
# -Country can be listed out in either State/Province or City
# -State_or_Province may contain only US States without listing Country
# -City may only contain the name of the Country
#-------------------------------------------------------------------
# Split job_location to City, State/Province, and Country
job_postings_clean<- job_postings %>%
separate_wider_delim(cols = job_location,
delim=",",
names=c("Ci", "SoP", "Co"),
too_few = 'align_start',
too_many = 'merge')
# Cleaning up the data in job_posting
job_postings_clean <- job_postings_clean %>%
# trim white space for City, State/Province, and Country
mutate(Ci = str_trim(Ci),
SoP = str_trim(SoP),
Co = str_trim(Co)) %>%
# set empty spaces to null
mutate(Ci = na_if(Ci,""),
SoP = na_if(SoP,""),
Co = na_if(Co,""))
# Helper Columns to see if city or state contains country
job_postings_clean <- job_postings_clean %>%
mutate(
# Check if city contains country
matchCity = sapply(Ci, function(x) {
matches <- regmatches(x, regexpr(Countries, x))
if (length(matches) > 0) matches else NA
}
),
# Check if State contains country
matchSoP1 = sapply(SoP, function(x) {
matches <- regmatches(x, regexpr(Countries, x))
if (length(matches) > 0) matches else NA
}
),
# check if States contains the 50 US states
matchSoP2 = sapply(SoP, function(x) {
matches <- regmatches(x, regexpr(States, x))
if (length(matches) > 0) "United States" else NA
}
),
matSoP = coalesce(matchSoP1, matchSoP2)
)
job_postings_clean <- job_postings_clean %>%
mutate(
# Check the cases for when Country is empty
Country = case_when(
!is.na(Co) ~ Co,
!is.na(matSoP) ~ matSoP,
!is.na(matchCity) ~ matchCity,
is.na(Ci) ~ NA,
TRUE ~ NA
),
# Check the cases for when State or Province does not have Country name
State_or_Province = ifelse(is.na(matchSoP1),SoP, NA),
# Check the cases for when City does not contain State or Country
City = case_when(
!is.na(State_or_Province) ~ Ci,
is.na(matchCity) ~ Ci,
Country != matchCity ~ Ci,
TRUE ~ NA
)
) %>%
# Remove helper columns
select(-c(Ci, SoP, Co, matchCity,matchSoP1,matchSoP2,matSoP))
#Extract date from last_processing column:
job_postings_clean$last_process_date<- format(as.Date(job_postings_clean$last_processed_time), format = "%m-%d-%Y")
job_postings_clean <-  job_postings_clean%>%
select(-c(last_processed_time))
head(job_postings_clean)
# Normalized skills table with skill_ID assigned
Skills_Normalized <- job_skills_clean %>%
drop_na(Skills) %>%
arrange(Skills) %>%
distinct(Skills) %>%
mutate(Skill_ID = 1:n())
Skills_Normalized$Skills<- gsub("[\"*]","", Skills_Normalized$Skills)
head(Skills_Normalized)
# Normalized company table with Company_ID assigned
Company_Normalized <- job_postings_clean %>%
#Removing duplicate rows across company, city, and state_or_province or company per location ID creation
distinct(company, City, State_or_Province, Country, .keep_all = TRUE) %>%
mutate(Company_id = row_number()) %>%
relocate(Company_id, .before = 1) %>%
select(Company_id, Company = company, City, State_or_Province, Country)
head(Company_Normalized)
# Normalized Job_Listings table
Job_Listing_Normalized <- job_postings_clean %>%
left_join(Company_Normalized, join_by(company == Company, City== City, State_or_Province==State_or_Province, Country==Country), relationship = "many-to-many") %>%
select(job_ID, job_title, job_type, job_level, Company_id)
head(Job_Listing_Normalized)
# Normalized Listing_Skills table
Listing_Skills_Normalized <- job_skills_clean %>%
left_join(Skills_Normalized)
Listing_Skills_Normalized <- Listing_Skills_Normalized %>%
select(job_ID, Skill_ID)
head(Listing_Skills_Normalized)
job_skills_clean$Skills<- gsub("[\"*]","", job_skills_clean$Skills)
job_skills_clean$Skills<- gsub("SKILLS", "", job_skills_clean$Skills)
view(job_skills_clean)
job_skills_clean$Skills<- gsub("SKILLS$", "", job_skills_clean$Skills)
job_skills_clean
Top_ten_skills<- job_skills_clean %>%
count(Skills) %>%
slice_max(n, n=10)
ggplot(Top_ten_skills, aes(x=reorder(Skills, n), y = n, fill=n))+
geom_bar(stat='identity') +
labs(title='Top 10 data science skills from LinkedIn job posting 2024',
x="", y='Number of postings')+
theme(axis.text.x = element_text(angle=47, hjust = 1),
legend.position='') +
coord_flip()
job_skills_clean$Skills<- trimws(gsub("SKILLS$", "", job_skills_clean$Skills))
job_skills_clean
Top_ten_skills<- job_skills_clean %>%
count(Skills) %>%
slice_max(n, n=10)
ggplot(Top_ten_skills, aes(x=reorder(Skills, n), y = n, fill=n))+
geom_bar(stat='identity') +
labs(title='Top 10 data science skills from LinkedIn job posting 2024',
x="", y='Number of postings')+
theme(axis.text.x = element_text(angle=47, hjust = 1),
legend.position='') +
coord_flip()
ggplot(Top_ten_skills, aes(x=reorder(Skills, n), y = n, fill=n))+
geom_bar(stat='identity') +
labs(title='Top 10 data science skills from LinkedIn job posting 2024',
x="", y='Number of appearance')+
theme(axis.text.x = element_text(angle=47, hjust = 1),
legend.position='') +
coord_flip()
ggplot(Top_ten_skills, aes(x=reorder(Skills, n), y = n, fill=n))+
geom_bar(stat='identity') +
labs(title='Top 10 data science skills from LinkedIn job posting 2024',
x="", y='Number of appearance in job posting')+
theme(axis.text.x = element_text(angle=47, hjust = 1),
legend.position='') +
coord_flip()
senior_lv<- job_postings_clean %>%
filter(job_level=='Mid senior')
senior_skills<- job_skills_clean %>%
left_join(senior_lv) %>%
count(Skills) %>%
slice_max(n, n=10)
ggplot(senior_skills, aes(x=reorder(Skills, n), y=n))+
geom_bar(stat='identity')
job_num<- job_postings_clean %>%
drop_na(State_or_Province) %>%
filter(Country=='United States') %>%
count(State_or_Province) %>%
slice_max(n, n=5)
ggplot(job_num, aes(x=reorder(State_or_Province, n), y=n, fill=n))+
geom_bar(stat='identity')
ggplot(job_num, aes(x=reorder(State_or_Province, n), y=n, fill=n))+
geom_bar(stat='identity') +
labs(title = 'Top 5 States in the US that has the most DS job postings',
y='Number of jobs',
x='State Names') +
theme(legend.position = '')
ggplot(job_num, aes(x=reorder(State_or_Province, n), y=n, fill=n))+
geom_bar(stat='identity') +
labs(title = 'Top 5 States in the US that has the most DS job postings',
y='Number of jobs',
x='State Names') +
theme(legend.position = '') +
theme_minimal()
ggplot(job_num, aes(x=reorder(State_or_Province, n), y=n, fill=n))+
geom_bar(stat='identity') +
labs(title = 'Top 5 States in the US that has the most DS job postings',
y='Number of jobs',
x='State Names') +
theme(legend.position = '') +
theme_minimal(legend.position= '')
ggplot(job_num, aes(x=reorder(State_or_Province, n), y=n, fill=n))+
geom_bar(stat='identity') +
labs(title = 'Top 5 States in the US that has the most DS job postings',
y='Number of jobs',
x='State Names') +
theme(legend.position = '') +
theme_minimal()
ggplot(job_num, aes(x=reorder(State_or_Province, n), y=n, fill=n))+
geom_bar(stat='identity') +
labs(title = 'Top 5 States in the US that has the most DS job postings',
y='Number of jobs',
x='States') +
theme(legend.position = 'none') +
theme_minimal()
ggplot(job_num, aes(x=reorder(State_or_Province, n), y=n))+
geom_bar(stat='identity', aes(fill=n)) +
labs(title = 'Top 5 States in the US that has the most DS job postings',
y='Number of jobs',
x='States') +
theme(legend.position = 'none') +
theme_minimal()
ggplot(job_num, aes(x=reorder(State_or_Province, n), y=n))+
geom_bar(stat='identity', aes(fill=n)) +
labs(title = 'Top 5 States in the US that has the most DS job postings',
y='Number of jobs',
x='States') +
theme(legend.position = '') +
theme_minimal()
ggplot(job_num, aes(x=reorder(State_or_Province, n), y=n))+
geom_bar(stat='identity', aes(fill=n)) +
labs(title = 'Top 5 States in the US that has the most DS job postings',
y='Number of jobs',
x='States') +
theme(legend.position = '')
